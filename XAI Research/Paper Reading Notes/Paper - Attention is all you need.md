1. **Transduction**: 
   In [logic](https://en.wikipedia.org/wiki/Logic "Logic"), [statistical inference](https://en.wikipedia.org/wiki/Statistical_inference "Statistical inference"), and [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning "Supervised learning"), transduction or transductive inference is [reasoning](https://en.wikipedia.org/wiki/Reasoning "Reasoning") from observed, specific (training) cases to specific (test) cases. In contrast, [induction](https://en.wikipedia.org/wiki/Induction_(philosophy) "Induction (philosophy)") is reasoning from observed training cases to general rules, which are then applied to the test cases. The distinction is most interesting in cases where the predictions of the transductive model are not achievable by any inductive model. Note that this is caused by transductive inference on different test sets producing mutually inconsistent predictions.
   Transduction was introduced by [Vladimir Vapnik](https://en.wikipedia.org/wiki/Vladimir_Vapnik "Vladimir Vapnik") in the 1990s, motivated by his view that transduction is preferable to induction since, according to him, induction requires solving a more general problem (inferring a function) before solving a more specific problem (computing outputs for new cases): "When solving a problem of interest, do not solve a more general problem as an intermediate step. Try to get the answer that you really need but not a more general one."[[1]](https://en.wikipedia.org/wiki/Transduction_(machine_learning)#cite_note-1) A similar observation had been made earlier by [Bertrand Russell](https://en.wikipedia.org/wiki/Bertrand_Russell "Bertrand Russell"): "we shall reach the conclusion that Socrates is mortal with a greater approach to certainty if we make our argument purely inductive than if we go by way of 'all men are mortal' and then use deduction" (Russell 1912, chap VII).
2. **Auto-Regressive Model**: 
   A ML model that solely depend on the previous value to make prediction.
3. 